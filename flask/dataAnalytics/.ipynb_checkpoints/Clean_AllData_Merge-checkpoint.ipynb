{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only needed on retraining\n",
    "#host=\"dublinbikes.c4oldfsyzoll.us-east-1.rds.amazonaws.com\"\n",
    "#port=3306\n",
    "#dbname=\"dublinBikes\"\n",
    "#user=\"TheATeam2019\"\n",
    "#password=\"SoftEng2019\"\n",
    "\n",
    "#conn = pymysql.connect(host, user=user,port=port,passwd=password, db=dbname)\n",
    "#query = \"SELECT * FROM dynamicData\"\n",
    "#df = pd.read_sql(query, conn)\n",
    "#query = \"SELECT * FROM dynamicData WHERE last_update BETWEEN '2019-02-01 00:00:00' AND '2019-03-17 00:00:00'\"\n",
    "#df = pd.read_sql(query, conn)\n",
    "#conn = pymysql.connect(host, user=user,port=port,passwd=password, db=dbname)\n",
    "#query = \"SELECT * FROM dynamicData WHERE last_update BETWEEN '2019-02-01 00:00:00' AND '2019-03-17 00:00:00'\"\n",
    "#df1 = pd.read_sql(query, conn)\n",
    "#query = \"SELECT number, name, banking FROM latest_info\"\n",
    "#dfdict=pd.read_sql(query, conn)\n",
    "#query = \"SELECT * FROM dynamicWeather\"\n",
    "#df2=pd.read_sql(query, conn)\n",
    "#conn.close()\n",
    "#df.to_csv('DataMar30.csv', index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "#df1.to_csv('DataMar28_test.csv', index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "#df2.to_csv('WeatherMar28.csv', index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "#dfdict.to_csv('NameNumberbanking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('DataAPR4.csv')\n",
    "df1 = pd.read_csv('WeatherAPR4.csv')\n",
    "dfdict=pd.read_csv('NameNumberbanking.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()\n",
    "df1=df1.drop_duplicates()\n",
    "df1['last_time'] = df1['last_time'].astype('datetime64[ns]')\n",
    "df['last_update'] = df['last_update'].astype('datetime64[ns]')\n",
    "df=df.sort_values('last_update')\n",
    "df1=df1.sort_values('last_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins the data with a time tolerance of 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.merge_asof(df, df1, left_on='last_update', right_on='last_time', direction='nearest')\n",
    "df=pd.merge_asof(df, df1, left_on='last_update', right_on='last_time', direction='nearest', tolerance=pd.Timedelta(hours=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdict['name']=dfdict['name'].astype('category')\n",
    "nameNodict=dict()\n",
    "for i in dfdict.loc[(dfdict['number'].notnull())].index:\n",
    "    key=dfdict.at[i, 'name']\n",
    "    nameNodict[key]=int(dfdict.at[i, 'number'])\n",
    "for i in df.index:\n",
    "    df.at[i,'number']=nameNodict[df.at[i, 'name']]\n",
    "#no need to format banking as it is continuous and will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[(df.loc[df.visibility>=0].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: MONDAY = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number']=df['number'].astype(int)\n",
    "df['day']=df['last_update'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"]=df['last_update'].dt.round('30min')  \n",
    "df['time']=df[\"time\"].dt.strftime('%H%M')\n",
    "#df=df.drop(['last_update'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROP SPECIAL HOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop special hols because they throw the data.\n",
    "drop=list(df.loc[(df['last_update'].dt.year==2019) &(df['last_update'].dt.month==3) & (df['last_update'].dt.day==17)].index)\n",
    "drop1=list(df.loc[(df['last_update'].dt.year==2019)&(df['last_update'].dt.month==3) & (df['last_update'].dt.day==18)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop)\n",
    "df = df.drop(drop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['avail_bikes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']=df.time.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"outfile = open('bins_dict','wb')\\npickle.dump(BINS,outfile)\\noutfile.close()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"outfile = open('bins_dict','wb')\n",
    "pickle.dump(BINS,outfile)\n",
    "outfile.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weather integer encoding\n",
    "df['raining']=0\n",
    "df['cloudy']=None\n",
    "raining={'thunderstorm with light rain':1, 'thunderstorm with rain':5, 'thunderstorm with heavy rain':10,\\\n",
    "              'light thunderstorm':0, 'thunderstorm':0, 'heavy thunderstorm': 0, 'ragged thunderstorm':0,\\\n",
    "              'thunderstorm with light drizzle':0, 'thunderstorm with drizzle':0, \\\n",
    "              'thunderstorm with heavy drizzle':1, 'light intensity drizzle': 0, 'drizzle':0,\\\n",
    "         'heavy intensity drizzle':1, 'light intensity drizzle rain':0,\\\n",
    "         'drizzle rain':1, 'heavy intensity drizzle rain':1, 'shower rain and drizzle':1, \\\n",
    "         'heavy shower rain and drizzle':3, 'shower drizzle':0, 'light rain':1, 'moderate rain':5, \\\n",
    "         'heavy intensity rain':10, 'very heavy rain':10, 'extreme rain':10,\\\n",
    "         'freezing rain':5, 'light intensity shower rain':0, 'shower rain':0, 'heavy intensity shower rain':1,\\\n",
    "         'ragged shower rain':0, 'Light snow':0 ,'Snow': 5, 'Heavy snow':10, 'Sleet':10, 'Light shower sleet':0, \\\n",
    "         'Shower sleet':0,\\\n",
    "         'Light rain and snow':1, 'Rain and snow':5, 'Light shower snow':0, 'Shower snow':0, 'Heavy shower snow':5}\n",
    "for i in df.index:\n",
    "    if df.at[i, 'description'] in raining:\n",
    "        df.at[i,'raining']=raining[df.at[i,'description']]\n",
    "    if df.at[i, 'main'] =='Clouds':\n",
    "        if df.at[i,'description']=='overcast clouds':\n",
    "            df.at[i,'cloudy']=1\n",
    "#drop columns\n",
    "df=df.drop('main',1)\n",
    "df=df.drop('description',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outfile = open('raining','wb')\n",
    "pickle.dump(raining,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday']=1\n",
    "for i in df.loc[df['day'].isin([5,6])].index:\n",
    "    df.at[i,'weekday']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"name\", \"avail_bike_stands\", \"last_time\", 'banking', 'status', 'visibility'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=list(df.columns.values)\n",
    "l.remove('last_update')\n",
    "for feature in l:\n",
    "    if np.std(df[feature])==0:\n",
    "        df=df.drop(feature, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clampLB(minV,maxV, Q3, Q1):\n",
    "    return max(minV, Q1-1.5*(Q3-Q1))\n",
    "def clampUB(minV, maxV, Q3, Q1):\n",
    "    return min(maxV, Q3+1.5*(Q3-Q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691233, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save=df.copy(deep=True)\n",
    "save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df.copy(deep=True);\n",
    "for n in range(0, 113):\n",
    "    dn=df.loc[dt.number==n].copy(deep=True)\n",
    "    for day in range(0,7):\n",
    "        df=dn.loc[dt.day==day]\n",
    "        col='avail_bikes'\n",
    "        UB=clampUB(df[col].min(), df[col].max(), df[col].quantile(.75), df[col].quantile(.25))\n",
    "        for i in df.loc[(df[col]>=UB)].index:\n",
    "            dt.at[i, col]=UB\n",
    "        LB=clampLB(df[col].min(), df[col].max(), df[col].quantile(.75), df[col].quantile(.25))\n",
    "        for i in df.loc[(df[col]<=LB)].index:\n",
    "            dt.at[i, col]=LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS=pickle.load(open(\"time_dict\",\"rb\"))\n",
    "dt.time=dt.time.replace(BINS)\n",
    "RushHour=dict()\n",
    "meandict=dict()\n",
    "dt['rush_hr']=0 ##new\n",
    "for s in dt['number'].unique():\n",
    "    Models=dict()\n",
    "    df=dt.loc[(dt['number']==s)]\n",
    "    meandict[s]={0:{},1:{},2:{},3:{},4:{},5:{},6:{}}\n",
    "    for day in range(0,7):\n",
    "        df1=df.loc[(df['day']==day)]\n",
    "        df1=df1.sort_values(['time'])\n",
    "        mean=list(round(df1.groupby('time')['avail_bikes'].mean()))\n",
    "        time=list(df1.time.unique())\n",
    "        for i in range(0, len(mean)):\n",
    "            meandict[s][day][time[i]]=mean[i]\n",
    "    RushHour[s]=dict()\n",
    "    df1=df1.reset_index(drop=True)\n",
    "    stands=df1.bike_stands[0]\n",
    "    for day in range(0,7):\n",
    "        RushHour[s][day]=dict()\n",
    "        for i in df.loc[df['day']==day].index:\n",
    "            if meandict[s][day][df.at[i, 'time']]<round(.2*stands):\n",
    "                dt.at[i,'rush_hr']=1\n",
    "                RushHour[s][day][df.at[i, 'time']]=1\n",
    "            else:\n",
    "                RushHour[s][day][df.at[i, 'time']]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_csv('DataCleanedAPR4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dublinBikes]",
   "language": "python",
   "name": "conda-env-dublinBikes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
